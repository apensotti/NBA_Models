{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\\scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transform_db\n",
    "from transform_db import load_clean\n",
    "from transform_db import transform\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\alexp\\\\src\\\\NBA_Models\\\\sqlite\\\\db\\\\nba_data.db\"\n",
    "load = load_clean(path)\n",
    "agg_boxscores = load.agg_boxscores_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(path)\n",
    "\n",
    "clean = transform(conn,2013,2023)\n",
    "data = clean.load_team_data()\n",
    "data = clean.clean_team_data(data)\n",
    "data = data.dropna(subset='PCT_PTS_2PT')\n",
    "data = clean.convert_pcts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_df = data.loc[:,data.columns[9:]]\n",
    "scaled_array = scaler.fit_transform(scaled_df)\n",
    "scaled = pd.DataFrame(scaled_array,columns=scaled_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_columns = data.loc[:,data.columns[:9]]\n",
    "data[scaled.columns] = scaled.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Input Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(data['TEAM_ABBREVIATION'])\n",
    "\n",
    "data['TEAM_ABBREVIATION'] = encoder.transform(data['TEAM_ABBREVIATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = ['SEASON',\"TEAM_ID\",'TEAM_NAME','GAME_ID','GAME_DATE','MATCHUP']\n",
    "data_clean = data[data.columns.difference(filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23422, 10, 34), (23422,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "window_size = 10\n",
    "\n",
    "for i in range(len(data_clean['TEAM_ABBREVIATION'].unique())):\n",
    "    team = data_clean.loc[data_clean['TEAM_ABBREVIATION'] == i]\n",
    "    team_label = team['WL'].copy()\n",
    "    team = team.drop('WL',axis=1)\n",
    "\n",
    "    team_np = team.to_numpy()\n",
    "    team_label = team_label.to_numpy()\n",
    "\n",
    "    #temp_X = []\n",
    "    #temp_y = []\n",
    "    \n",
    "    for i in range(len(team_np)-window_size):        \n",
    "      row = [a for a in team_np[i:i+window_size]]\n",
    "      X_list.append(row)\n",
    "\n",
    "      label = team_label[i+window_size]\n",
    "      y_list.append(label)\n",
    "\n",
    "X_list = np.array(X_list)\n",
    "y_list = np.array(y_list)\n",
    "\n",
    "X_list.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from model import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig(X_list,y_list,[.75,.10,.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.train_test_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                25344     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25873 (101.07 KB)\n",
      "Trainable params: 25873 (101.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = model_config.create_sequential()\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(8,'relu'))\n",
    "model.add(Dense(1,'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('is_cuda_build', False),\n",
       "             ('is_rocm_build', False),\n",
       "             ('is_tensorrt_build', False),\n",
       "             ('msvcp_dll_names', 'msvcp140.dll,msvcp140_1.dll')])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.sysconfig.get_build_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
