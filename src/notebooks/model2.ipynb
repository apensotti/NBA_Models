{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\\scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transform_db\n",
    "from transform_db import load_clean\n",
    "from transform_db import transform\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\alexp\\\\src\\\\NBA_Models\\\\sqlite\\\\db\\\\nba_data.db\"\n",
    "load = load_clean(path)\n",
    "agg_boxscores = load.agg_boxscores_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(path)\n",
    "\n",
    "clean = transform(conn,2013,2023)\n",
    "data = clean.load_team_data()\n",
    "data = clean.clean_team_data(data)\n",
    "data = data.dropna(subset='PCT_PTS_2PT')\n",
    "data = clean.convert_pcts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>HOME_GAME</th>\n",
       "      <th>WL</th>\n",
       "      <th>FG2M</th>\n",
       "      <th>FG2A</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>E_OFF_RATING</th>\n",
       "      <th>OFF_RATING</th>\n",
       "      <th>E_DEF_RATING</th>\n",
       "      <th>DEF_RATING</th>\n",
       "      <th>E_NET_RATING</th>\n",
       "      <th>NET_RATING</th>\n",
       "      <th>POSS</th>\n",
       "      <th>PIE</th>\n",
       "      <th>PTS_2PT_MR</th>\n",
       "      <th>PTS_FB</th>\n",
       "      <th>PTS_OFF_TOV</th>\n",
       "      <th>PTS_PAINT</th>\n",
       "      <th>AST_2PM</th>\n",
       "      <th>AST_3PM</th>\n",
       "      <th>UAST_2PM</th>\n",
       "      <th>UAST_3PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26673</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>3</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>0022300484</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>CHA @ CHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.581767</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>0.441333</td>\n",
       "      <td>-1.430537</td>\n",
       "      <td>-1.484801</td>\n",
       "      <td>0.448450</td>\n",
       "      <td>-0.658792</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>-0.713543</td>\n",
       "      <td>-0.203176</td>\n",
       "      <td>-1.542274</td>\n",
       "      <td>-0.281618</td>\n",
       "      <td>-0.052662</td>\n",
       "      <td>-1.300038</td>\n",
       "      <td>-0.910616</td>\n",
       "      <td>-1.028633</td>\n",
       "      <td>-0.996675</td>\n",
       "      <td>0.430480</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>-1.143789</td>\n",
       "      <td>-0.972063</td>\n",
       "      <td>-1.025825</td>\n",
       "      <td>-1.514670</td>\n",
       "      <td>0.620448</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>-0.932400</td>\n",
       "      <td>-0.998095</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26674</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>18</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>0022300486</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>NOP vs. LAC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.524655</td>\n",
       "      <td>0.715610</td>\n",
       "      <td>0.285284</td>\n",
       "      <td>-0.156687</td>\n",
       "      <td>-0.093433</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>0.976450</td>\n",
       "      <td>-0.842345</td>\n",
       "      <td>-0.134496</td>\n",
       "      <td>-0.329209</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>0.062508</td>\n",
       "      <td>-1.298793</td>\n",
       "      <td>-0.754486</td>\n",
       "      <td>-0.998035</td>\n",
       "      <td>-1.120757</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>-0.712071</td>\n",
       "      <td>0.722302</td>\n",
       "      <td>0.754066</td>\n",
       "      <td>-1.218237</td>\n",
       "      <td>-1.180363</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-1.241352</td>\n",
       "      <td>-1.221566</td>\n",
       "      <td>-0.248569</td>\n",
       "      <td>0.174985</td>\n",
       "      <td>-0.738266</td>\n",
       "      <td>-0.540766</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>-1.411359</td>\n",
       "      <td>0.810381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26675</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>12</td>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>0022300486</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>LAC @ NOP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.770345</td>\n",
       "      <td>-1.169557</td>\n",
       "      <td>1.016748</td>\n",
       "      <td>0.680541</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>1.176736</td>\n",
       "      <td>0.922815</td>\n",
       "      <td>0.823795</td>\n",
       "      <td>-0.545926</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>0.226969</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>0.209974</td>\n",
       "      <td>1.120745</td>\n",
       "      <td>0.722311</td>\n",
       "      <td>0.754069</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>-0.712069</td>\n",
       "      <td>1.218245</td>\n",
       "      <td>1.180363</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>1.241289</td>\n",
       "      <td>-0.371406</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>-1.451391</td>\n",
       "      <td>-0.641199</td>\n",
       "      <td>0.373890</td>\n",
       "      <td>0.946218</td>\n",
       "      <td>-1.173008</td>\n",
       "      <td>0.810381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26676</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>17</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>0022300485</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>MIN @ HOU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549699</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>0.321729</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.343549</td>\n",
       "      <td>1.727394</td>\n",
       "      <td>1.224904</td>\n",
       "      <td>1.400297</td>\n",
       "      <td>1.510572</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>-0.027325</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>1.040480</td>\n",
       "      <td>1.891262</td>\n",
       "      <td>1.057051</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>-1.432033</td>\n",
       "      <td>-1.238153</td>\n",
       "      <td>1.962725</td>\n",
       "      <td>1.708055</td>\n",
       "      <td>0.519677</td>\n",
       "      <td>1.958749</td>\n",
       "      <td>-1.079873</td>\n",
       "      <td>1.143440</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>1.397211</td>\n",
       "      <td>0.831219</td>\n",
       "      <td>1.226725</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>-1.023665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26677</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>24</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>0022300487</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>POR @ DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.581767</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.529105</td>\n",
       "      <td>1.158958</td>\n",
       "      <td>-0.929123</td>\n",
       "      <td>-0.799476</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-0.291687</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>0.631628</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>-0.739883</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>-1.222369</td>\n",
       "      <td>-0.394031</td>\n",
       "      <td>-2.521696</td>\n",
       "      <td>-1.294708</td>\n",
       "      <td>-1.281279</td>\n",
       "      <td>1.657850</td>\n",
       "      <td>1.564752</td>\n",
       "      <td>-2.328189</td>\n",
       "      <td>-2.291292</td>\n",
       "      <td>1.721734</td>\n",
       "      <td>-1.708271</td>\n",
       "      <td>-0.513099</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>0.825536</td>\n",
       "      <td>-0.252930</td>\n",
       "      <td>0.145226</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>-0.934656</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SEASON     TEAM_ID  TEAM_ABBREVIATION               TEAM_NAME  \\\n",
       "26673  2023-24  1610612766                  3       Charlotte Hornets   \n",
       "26674  2023-24  1610612740                 18    New Orleans Pelicans   \n",
       "26675  2023-24  1610612746                 12             LA Clippers   \n",
       "26676  2023-24  1610612750                 17  Minnesota Timberwolves   \n",
       "26677  2023-24  1610612757                 24  Portland Trail Blazers   \n",
       "\n",
       "          GAME_ID  GAME_DATE      MATCHUP  HOME_GAME  WL      FG2M      FG2A  \\\n",
       "26673  0022300484 2024-01-05    CHA @ CHI          0   0 -0.581767 -0.171527   \n",
       "26674  0022300486 2024-01-05  NOP vs. LAC          1   0 -1.524655  0.715610   \n",
       "26675  0022300486 2024-01-05    LAC @ NOP          0   1 -0.770345 -1.169557   \n",
       "26676  0022300485 2024-01-05    MIN @ HOU          0   1  0.549699 -0.171527   \n",
       "26677  0022300487 2024-01-05    POR @ DAL          0   0 -0.581767 -0.171527   \n",
       "\n",
       "           FG3M      FG3A       FTM       FTA      OREB      DREB       REB  \\\n",
       "26673 -0.202359  0.441333 -1.430537 -1.484801  0.448450 -0.658792 -0.285540   \n",
       "26674  0.285284 -0.156687 -0.093433  0.022915  0.976450 -0.842345 -0.134496   \n",
       "26675  1.016748  0.680541 -0.260571 -0.388280 -0.079549  1.176736  0.922815   \n",
       "26676  0.772927  0.321729 -0.260571 -0.388280 -0.343549  1.727394  1.224904   \n",
       "26677  0.529105  1.158958 -0.929123 -0.799476 -0.079549 -0.291687 -0.285540   \n",
       "\n",
       "            AST       STL       BLK       TOV        PF       PTS  PLUS_MINUS  \\\n",
       "26673 -0.713543 -0.203176 -1.542274 -0.281618 -0.052662 -1.300038   -0.910616   \n",
       "26674 -0.329209  0.482323  0.062508 -1.298793 -0.754486 -0.998035   -1.120757   \n",
       "26675  0.823795 -0.545926  0.864899  0.226969 -0.520545  0.209974    1.120745   \n",
       "26676  1.400297  1.510572  0.864899 -0.027325 -0.520545  1.040480    1.891262   \n",
       "26677  0.631628  0.482323 -0.739883  1.244144 -1.222369 -0.394031   -2.521696   \n",
       "\n",
       "       E_OFF_RATING  OFF_RATING  E_DEF_RATING  DEF_RATING  E_NET_RATING  \\\n",
       "26673     -1.028633   -0.996675      0.430480    0.210733     -1.143789   \n",
       "26674     -0.831223   -0.712071      0.722302    0.754066     -1.218237   \n",
       "26675      0.722311    0.754069     -0.831223   -0.712069      1.218245   \n",
       "26676      1.057051    0.883434     -1.432033   -1.238153      1.962725   \n",
       "26677     -1.294708   -1.281279      1.657850    1.564752     -2.328189   \n",
       "\n",
       "       NET_RATING      POSS       PIE  PTS_2PT_MR    PTS_FB  PTS_OFF_TOV  \\\n",
       "26673   -0.972063 -1.025825 -1.514670    0.620448 -0.403236     0.012348   \n",
       "26674   -1.180363 -0.854102 -1.241352   -1.221566 -0.248569     0.174985   \n",
       "26675    1.180363 -0.854102  1.241289   -0.371406 -0.093901    -1.451391   \n",
       "26676    1.708055  0.519677  1.958749   -1.079873  1.143440     0.337623   \n",
       "26677   -2.291292  1.721734 -1.708271   -0.513099 -0.093901     0.825536   \n",
       "\n",
       "       PTS_PAINT   AST_2PM   AST_3PM  UAST_2PM  UAST_3PM  \n",
       "26673  -0.932400 -0.998095  0.104697  0.257100 -0.412316  \n",
       "26674  -0.738266 -0.540766  0.104697 -1.411359  0.810381  \n",
       "26675  -0.641199  0.373890  0.946218 -1.173008  0.810381  \n",
       "26676   1.397211  0.831219  1.226725  0.018749 -1.023665  \n",
       "26677  -0.252930  0.145226  0.665711 -0.934656 -0.412316  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SEASON\n",
      "1 TEAM_ID\n",
      "2 TEAM_ABBREVIATION\n",
      "3 TEAM_NAME\n",
      "4 GAME_ID\n",
      "5 GAME_DATE\n",
      "6 MATCHUP\n",
      "7 HOME_GAME\n",
      "8 WL\n",
      "9 FG2M\n",
      "10 FG2A\n",
      "11 FG3M\n",
      "12 FG3A\n",
      "13 FTM\n",
      "14 FTA\n",
      "15 OREB\n",
      "16 DREB\n",
      "17 REB\n",
      "18 AST\n",
      "19 STL\n",
      "20 BLK\n",
      "21 TOV\n",
      "22 PF\n",
      "23 PTS\n",
      "24 PLUS_MINUS\n",
      "25 E_OFF_RATING\n",
      "26 OFF_RATING\n",
      "27 E_DEF_RATING\n",
      "28 DEF_RATING\n",
      "29 E_NET_RATING\n",
      "30 NET_RATING\n",
      "31 POSS\n",
      "32 PIE\n",
      "33 PTS_2PT_MR\n",
      "34 PTS_FB\n",
      "35 PTS_OFF_TOV\n",
      "36 PTS_PAINT\n",
      "37 AST_2PM\n",
      "38 AST_3PM\n",
      "39 UAST_2PM\n",
      "40 UAST_3PM\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(data.columns):\n",
    "    print(i, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_df = data.loc[:,data.columns[9:]]\n",
    "scaled_array = scaler.fit_transform(scaled_df)\n",
    "scaled = pd.DataFrame(scaled_array,columns=scaled_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FG2M</th>\n",
       "      <th>FG2A</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>E_OFF_RATING</th>\n",
       "      <th>OFF_RATING</th>\n",
       "      <th>E_DEF_RATING</th>\n",
       "      <th>DEF_RATING</th>\n",
       "      <th>E_NET_RATING</th>\n",
       "      <th>NET_RATING</th>\n",
       "      <th>POSS</th>\n",
       "      <th>PIE</th>\n",
       "      <th>PTS_2PT_MR</th>\n",
       "      <th>PTS_FB</th>\n",
       "      <th>PTS_OFF_TOV</th>\n",
       "      <th>PTS_PAINT</th>\n",
       "      <th>AST_2PM</th>\n",
       "      <th>AST_3PM</th>\n",
       "      <th>UAST_2PM</th>\n",
       "      <th>UAST_3PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.738276</td>\n",
       "      <td>0.604718</td>\n",
       "      <td>-0.690002</td>\n",
       "      <td>-1.113520</td>\n",
       "      <td>-0.761985</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-0.658792</td>\n",
       "      <td>-0.587629</td>\n",
       "      <td>0.631628</td>\n",
       "      <td>1.167823</td>\n",
       "      <td>-0.338687</td>\n",
       "      <td>0.481263</td>\n",
       "      <td>0.181279</td>\n",
       "      <td>-0.394031</td>\n",
       "      <td>-0.910616</td>\n",
       "      <td>-0.307656</td>\n",
       "      <td>-0.367097</td>\n",
       "      <td>0.138657</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>-0.351932</td>\n",
       "      <td>-0.840140</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>-0.034196</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>0.834105</td>\n",
       "      <td>1.476086</td>\n",
       "      <td>0.135338</td>\n",
       "      <td>1.059883</td>\n",
       "      <td>-0.456318</td>\n",
       "      <td>-0.219602</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.204612</td>\n",
       "      <td>0.826502</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>-0.156687</td>\n",
       "      <td>0.073705</td>\n",
       "      <td>0.708241</td>\n",
       "      <td>2.032450</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>1.224904</td>\n",
       "      <td>-0.137041</td>\n",
       "      <td>0.139573</td>\n",
       "      <td>0.463704</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>0.649162</td>\n",
       "      <td>0.587477</td>\n",
       "      <td>0.910605</td>\n",
       "      <td>0.138663</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>-0.307659</td>\n",
       "      <td>-0.367096</td>\n",
       "      <td>0.351940</td>\n",
       "      <td>0.840141</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>0.337061</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>1.801361</td>\n",
       "      <td>-0.447064</td>\n",
       "      <td>-0.540766</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.199032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.393189</td>\n",
       "      <td>1.935424</td>\n",
       "      <td>-0.446180</td>\n",
       "      <td>-1.352728</td>\n",
       "      <td>-1.931951</td>\n",
       "      <td>-1.758932</td>\n",
       "      <td>0.712450</td>\n",
       "      <td>-1.393003</td>\n",
       "      <td>-0.738674</td>\n",
       "      <td>-1.290045</td>\n",
       "      <td>0.825073</td>\n",
       "      <td>0.463704</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>1.350987</td>\n",
       "      <td>-1.602040</td>\n",
       "      <td>-0.700475</td>\n",
       "      <td>-2.007102</td>\n",
       "      <td>-1.445142</td>\n",
       "      <td>-0.556566</td>\n",
       "      <td>-0.530958</td>\n",
       "      <td>-1.137021</td>\n",
       "      <td>-0.735991</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-1.833541</td>\n",
       "      <td>1.187221</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.662898</td>\n",
       "      <td>-1.126534</td>\n",
       "      <td>-1.226759</td>\n",
       "      <td>-0.456318</td>\n",
       "      <td>0.733803</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393189</td>\n",
       "      <td>-0.282419</td>\n",
       "      <td>-0.933823</td>\n",
       "      <td>-1.591937</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>1.256502</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>-1.290045</td>\n",
       "      <td>-1.231425</td>\n",
       "      <td>5.278051</td>\n",
       "      <td>1.752731</td>\n",
       "      <td>-1.690252</td>\n",
       "      <td>-0.847034</td>\n",
       "      <td>0.700464</td>\n",
       "      <td>-0.556565</td>\n",
       "      <td>-0.530960</td>\n",
       "      <td>-2.007095</td>\n",
       "      <td>-1.445137</td>\n",
       "      <td>1.137029</td>\n",
       "      <td>0.735991</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>1.833478</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>2.126637</td>\n",
       "      <td>-1.029467</td>\n",
       "      <td>-0.769431</td>\n",
       "      <td>-1.297839</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.199032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.958922</td>\n",
       "      <td>-0.393311</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>-0.635104</td>\n",
       "      <td>1.076533</td>\n",
       "      <td>1.256502</td>\n",
       "      <td>0.712450</td>\n",
       "      <td>-1.576556</td>\n",
       "      <td>-0.889718</td>\n",
       "      <td>-0.137041</td>\n",
       "      <td>-0.888676</td>\n",
       "      <td>-0.739883</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>2.286753</td>\n",
       "      <td>-0.469531</td>\n",
       "      <td>-0.770522</td>\n",
       "      <td>-0.110245</td>\n",
       "      <td>-0.453341</td>\n",
       "      <td>0.516310</td>\n",
       "      <td>0.512585</td>\n",
       "      <td>-0.500828</td>\n",
       "      <td>-0.777651</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>-0.990810</td>\n",
       "      <td>1.045528</td>\n",
       "      <td>-0.712572</td>\n",
       "      <td>0.988173</td>\n",
       "      <td>-1.708937</td>\n",
       "      <td>-0.312102</td>\n",
       "      <td>0.385204</td>\n",
       "      <td>-0.934656</td>\n",
       "      <td>-1.023665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23717</th>\n",
       "      <td>-0.581767</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>0.441333</td>\n",
       "      <td>-1.430537</td>\n",
       "      <td>-1.484801</td>\n",
       "      <td>0.448450</td>\n",
       "      <td>-0.658792</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>-0.713543</td>\n",
       "      <td>-0.203176</td>\n",
       "      <td>-1.542274</td>\n",
       "      <td>-0.281618</td>\n",
       "      <td>-0.052662</td>\n",
       "      <td>-1.300038</td>\n",
       "      <td>-0.910616</td>\n",
       "      <td>-1.028633</td>\n",
       "      <td>-0.996675</td>\n",
       "      <td>0.430480</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>-1.143789</td>\n",
       "      <td>-0.972063</td>\n",
       "      <td>-1.025825</td>\n",
       "      <td>-1.514670</td>\n",
       "      <td>0.620448</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>-0.932400</td>\n",
       "      <td>-0.998095</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23718</th>\n",
       "      <td>-1.524655</td>\n",
       "      <td>0.715610</td>\n",
       "      <td>0.285284</td>\n",
       "      <td>-0.156687</td>\n",
       "      <td>-0.093433</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>0.976450</td>\n",
       "      <td>-0.842345</td>\n",
       "      <td>-0.134496</td>\n",
       "      <td>-0.329209</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>0.062508</td>\n",
       "      <td>-1.298793</td>\n",
       "      <td>-0.754486</td>\n",
       "      <td>-0.998035</td>\n",
       "      <td>-1.120757</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>-0.712071</td>\n",
       "      <td>0.722302</td>\n",
       "      <td>0.754066</td>\n",
       "      <td>-1.218237</td>\n",
       "      <td>-1.180363</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-1.241352</td>\n",
       "      <td>-1.221566</td>\n",
       "      <td>-0.248569</td>\n",
       "      <td>0.174985</td>\n",
       "      <td>-0.738266</td>\n",
       "      <td>-0.540766</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>-1.411359</td>\n",
       "      <td>0.810381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23719</th>\n",
       "      <td>-0.770345</td>\n",
       "      <td>-1.169557</td>\n",
       "      <td>1.016748</td>\n",
       "      <td>0.680541</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>1.176736</td>\n",
       "      <td>0.922815</td>\n",
       "      <td>0.823795</td>\n",
       "      <td>-0.545926</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>0.226969</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>0.209974</td>\n",
       "      <td>1.120745</td>\n",
       "      <td>0.722311</td>\n",
       "      <td>0.754069</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>-0.712069</td>\n",
       "      <td>1.218245</td>\n",
       "      <td>1.180363</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>1.241289</td>\n",
       "      <td>-0.371406</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>-1.451391</td>\n",
       "      <td>-0.641199</td>\n",
       "      <td>0.373890</td>\n",
       "      <td>0.946218</td>\n",
       "      <td>-1.173008</td>\n",
       "      <td>0.810381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23720</th>\n",
       "      <td>0.549699</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>0.321729</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.343549</td>\n",
       "      <td>1.727394</td>\n",
       "      <td>1.224904</td>\n",
       "      <td>1.400297</td>\n",
       "      <td>1.510572</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>-0.027325</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>1.040480</td>\n",
       "      <td>1.891262</td>\n",
       "      <td>1.057051</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>-1.432033</td>\n",
       "      <td>-1.238153</td>\n",
       "      <td>1.962725</td>\n",
       "      <td>1.708055</td>\n",
       "      <td>0.519677</td>\n",
       "      <td>1.958749</td>\n",
       "      <td>-1.079873</td>\n",
       "      <td>1.143440</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>1.397211</td>\n",
       "      <td>0.831219</td>\n",
       "      <td>1.226725</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>-1.023665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23721</th>\n",
       "      <td>-0.581767</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.529105</td>\n",
       "      <td>1.158958</td>\n",
       "      <td>-0.929123</td>\n",
       "      <td>-0.799476</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-0.291687</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>0.631628</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>-0.739883</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>-1.222369</td>\n",
       "      <td>-0.394031</td>\n",
       "      <td>-2.521696</td>\n",
       "      <td>-1.294708</td>\n",
       "      <td>-1.281279</td>\n",
       "      <td>1.657850</td>\n",
       "      <td>1.564752</td>\n",
       "      <td>-2.328189</td>\n",
       "      <td>-2.291292</td>\n",
       "      <td>1.721734</td>\n",
       "      <td>-1.708271</td>\n",
       "      <td>-0.513099</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>0.825536</td>\n",
       "      <td>-0.252930</td>\n",
       "      <td>0.145226</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>-0.934656</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23722 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           FG2M      FG2A      FG3M      FG3A       FTM       FTA      OREB  \\\n",
       "0      0.738276  0.604718 -0.690002 -1.113520 -0.761985  0.022915 -0.079549   \n",
       "1     -0.204612  0.826502  0.772927 -0.156687  0.073705  0.708241  2.032450   \n",
       "2     -0.393189  1.935424 -0.446180 -1.352728 -1.931951 -1.758932  0.712450   \n",
       "3     -0.393189 -0.282419 -0.933823 -1.591937  0.742257  1.256502 -0.079549   \n",
       "4     -0.958922 -0.393311 -0.202359 -0.635104  1.076533  1.256502  0.712450   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23717 -0.581767 -0.171527 -0.202359  0.441333 -1.430537 -1.484801  0.448450   \n",
       "23718 -1.524655  0.715610  0.285284 -0.156687 -0.093433  0.022915  0.976450   \n",
       "23719 -0.770345 -1.169557  1.016748  0.680541 -0.260571 -0.388280 -0.079549   \n",
       "23720  0.549699 -0.171527  0.772927  0.321729 -0.260571 -0.388280 -0.343549   \n",
       "23721 -0.581767 -0.171527  0.529105  1.158958 -0.929123 -0.799476 -0.079549   \n",
       "\n",
       "           DREB       REB       AST       STL       BLK       TOV        PF  \\\n",
       "0     -0.658792 -0.587629  0.631628  1.167823 -0.338687  0.481263  0.181279   \n",
       "1      0.075419  1.224904 -0.137041  0.139573  0.463704  1.244144  0.649162   \n",
       "2     -1.393003 -0.738674 -1.290045  0.825073  0.463704  1.244144  1.350987   \n",
       "3      0.075419  0.016549 -1.290045 -1.231425  5.278051  1.752731 -1.690252   \n",
       "4     -1.576556 -0.889718 -0.137041 -0.888676 -0.739883  0.735556  2.286753   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23717 -0.658792 -0.285540 -0.713543 -0.203176 -1.542274 -0.281618 -0.052662   \n",
       "23718 -0.842345 -0.134496 -0.329209  0.482323  0.062508 -1.298793 -0.754486   \n",
       "23719  1.176736  0.922815  0.823795 -0.545926  0.864899  0.226969 -0.520545   \n",
       "23720  1.727394  1.224904  1.400297  1.510572  0.864899 -0.027325 -0.520545   \n",
       "23721 -0.291687 -0.285540  0.631628  0.482323 -0.739883  1.244144 -1.222369   \n",
       "\n",
       "            PTS  PLUS_MINUS  E_OFF_RATING  OFF_RATING  E_DEF_RATING  \\\n",
       "0     -0.394031   -0.910616     -0.307656   -0.367097      0.138657   \n",
       "1      0.587477    0.910605      0.138663    0.676450     -0.307659   \n",
       "2     -1.602040   -0.700475     -2.007102   -1.445142     -0.556566   \n",
       "3     -0.847034    0.700464     -0.556565   -0.530960     -2.007095   \n",
       "4     -0.469531   -0.770522     -0.110245   -0.453341      0.516310   \n",
       "...         ...         ...           ...         ...           ...   \n",
       "23717 -1.300038   -0.910616     -1.028633   -0.996675      0.430480   \n",
       "23718 -0.998035   -1.120757     -0.831223   -0.712071      0.722302   \n",
       "23719  0.209974    1.120745      0.722311    0.754069     -0.831223   \n",
       "23720  1.040480    1.891262      1.057051    0.883434     -1.432033   \n",
       "23721 -0.394031   -2.521696     -1.294708   -1.281279      1.657850   \n",
       "\n",
       "       DEF_RATING  E_NET_RATING  NET_RATING      POSS       PIE  PTS_2PT_MR  \\\n",
       "0        0.676447     -0.351932   -0.840140 -0.167213 -0.034196    0.903834   \n",
       "1       -0.367096      0.351940    0.840141  0.004510  0.034133    0.337061   \n",
       "2       -0.530958     -1.137021   -0.735991 -0.854102 -1.833541    1.187221   \n",
       "3       -1.445137      1.137029    0.735991 -0.854102  1.833478    0.903834   \n",
       "4        0.512585     -0.500828   -0.777651 -0.167213 -0.990810    1.045528   \n",
       "...           ...           ...         ...       ...       ...         ...   \n",
       "23717    0.210733     -1.143789   -0.972063 -1.025825 -1.514670    0.620448   \n",
       "23718    0.754066     -1.218237   -1.180363 -0.854102 -1.241352   -1.221566   \n",
       "23719   -0.712069      1.218245    1.180363 -0.854102  1.241289   -0.371406   \n",
       "23720   -1.238153      1.962725    1.708055  0.519677  1.958749   -1.079873   \n",
       "23721    1.564752     -2.328189   -2.291292  1.721734 -1.708271   -0.513099   \n",
       "\n",
       "         PTS_FB  PTS_OFF_TOV  PTS_PAINT   AST_2PM   AST_3PM  UAST_2PM  \\\n",
       "0      0.834105     1.476086   0.135338  1.059883 -0.456318 -0.219602   \n",
       "1     -0.093901     1.801361  -0.447064 -0.540766  0.665711  0.257100   \n",
       "2     -0.403236     0.662898  -1.126534 -1.226759 -0.456318  0.733803   \n",
       "3     -0.093901     2.126637  -1.029467 -0.769431 -1.297839  0.257100   \n",
       "4     -0.712572     0.988173  -1.708937 -0.312102  0.385204 -0.934656   \n",
       "...         ...          ...        ...       ...       ...       ...   \n",
       "23717 -0.403236     0.012348  -0.932400 -0.998095  0.104697  0.257100   \n",
       "23718 -0.248569     0.174985  -0.738266 -0.540766  0.104697 -1.411359   \n",
       "23719 -0.093901    -1.451391  -0.641199  0.373890  0.946218 -1.173008   \n",
       "23720  1.143440     0.337623   1.397211  0.831219  1.226725  0.018749   \n",
       "23721 -0.093901     0.825536  -0.252930  0.145226  0.665711 -0.934656   \n",
       "\n",
       "       UAST_3PM  \n",
       "0     -0.412316  \n",
       "1      0.199032  \n",
       "2     -0.412316  \n",
       "3      0.199032  \n",
       "4     -1.023665  \n",
       "...         ...  \n",
       "23717 -0.412316  \n",
       "23718  0.810381  \n",
       "23719  0.810381  \n",
       "23720 -1.023665  \n",
       "23721 -0.412316  \n",
       "\n",
       "[23722 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_columns = data.loc[:,data.columns[:9]]\n",
    "\n",
    "data[scaled.columns] = scaled.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TEAM_NAME</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>HOME_GAME</th>\n",
       "      <th>WL</th>\n",
       "      <th>FG2M</th>\n",
       "      <th>FG2A</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>E_OFF_RATING</th>\n",
       "      <th>OFF_RATING</th>\n",
       "      <th>E_DEF_RATING</th>\n",
       "      <th>DEF_RATING</th>\n",
       "      <th>E_NET_RATING</th>\n",
       "      <th>NET_RATING</th>\n",
       "      <th>POSS</th>\n",
       "      <th>PIE</th>\n",
       "      <th>PTS_2PT_MR</th>\n",
       "      <th>PTS_FB</th>\n",
       "      <th>PTS_OFF_TOV</th>\n",
       "      <th>PTS_PAINT</th>\n",
       "      <th>AST_2PM</th>\n",
       "      <th>AST_3PM</th>\n",
       "      <th>UAST_2PM</th>\n",
       "      <th>UAST_3PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>LAC</td>\n",
       "      <td>Los Angeles Clippers</td>\n",
       "      <td>0021300003</td>\n",
       "      <td>2013-10-29</td>\n",
       "      <td>LAC @ LAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738276</td>\n",
       "      <td>0.604718</td>\n",
       "      <td>-0.690002</td>\n",
       "      <td>-1.113520</td>\n",
       "      <td>-0.761985</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-0.658792</td>\n",
       "      <td>-0.587629</td>\n",
       "      <td>0.631628</td>\n",
       "      <td>1.167823</td>\n",
       "      <td>-0.338687</td>\n",
       "      <td>0.481263</td>\n",
       "      <td>0.181279</td>\n",
       "      <td>-0.394031</td>\n",
       "      <td>-0.910616</td>\n",
       "      <td>-0.307656</td>\n",
       "      <td>-0.367097</td>\n",
       "      <td>0.138657</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>-0.351932</td>\n",
       "      <td>-0.840140</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>-0.034196</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>0.834105</td>\n",
       "      <td>1.476086</td>\n",
       "      <td>0.135338</td>\n",
       "      <td>1.059883</td>\n",
       "      <td>-0.456318</td>\n",
       "      <td>-0.219602</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>LAL</td>\n",
       "      <td>Los Angeles Lakers</td>\n",
       "      <td>0021300003</td>\n",
       "      <td>2013-10-29</td>\n",
       "      <td>LAL vs. LAC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.204612</td>\n",
       "      <td>0.826502</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>-0.156687</td>\n",
       "      <td>0.073705</td>\n",
       "      <td>0.708241</td>\n",
       "      <td>2.032450</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>1.224904</td>\n",
       "      <td>-0.137041</td>\n",
       "      <td>0.139573</td>\n",
       "      <td>0.463704</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>0.649162</td>\n",
       "      <td>0.587477</td>\n",
       "      <td>0.910605</td>\n",
       "      <td>0.138663</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>-0.307659</td>\n",
       "      <td>-0.367096</td>\n",
       "      <td>0.351940</td>\n",
       "      <td>0.840141</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>0.337061</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>1.801361</td>\n",
       "      <td>-0.447064</td>\n",
       "      <td>-0.540766</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.199032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>ORL</td>\n",
       "      <td>Orlando Magic</td>\n",
       "      <td>0021300001</td>\n",
       "      <td>2013-10-29</td>\n",
       "      <td>ORL @ IND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.393189</td>\n",
       "      <td>1.935424</td>\n",
       "      <td>-0.446180</td>\n",
       "      <td>-1.352728</td>\n",
       "      <td>-1.931951</td>\n",
       "      <td>-1.758932</td>\n",
       "      <td>0.712450</td>\n",
       "      <td>-1.393003</td>\n",
       "      <td>-0.738674</td>\n",
       "      <td>-1.290045</td>\n",
       "      <td>0.825073</td>\n",
       "      <td>0.463704</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>1.350987</td>\n",
       "      <td>-1.602040</td>\n",
       "      <td>-0.700475</td>\n",
       "      <td>-2.007102</td>\n",
       "      <td>-1.445142</td>\n",
       "      <td>-0.556566</td>\n",
       "      <td>-0.530958</td>\n",
       "      <td>-1.137021</td>\n",
       "      <td>-0.735991</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-1.833541</td>\n",
       "      <td>1.187221</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.662898</td>\n",
       "      <td>-1.126534</td>\n",
       "      <td>-1.226759</td>\n",
       "      <td>-0.456318</td>\n",
       "      <td>0.733803</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>1610612754</td>\n",
       "      <td>IND</td>\n",
       "      <td>Indiana Pacers</td>\n",
       "      <td>0021300001</td>\n",
       "      <td>2013-10-29</td>\n",
       "      <td>IND vs. ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.393189</td>\n",
       "      <td>-0.282419</td>\n",
       "      <td>-0.933823</td>\n",
       "      <td>-1.591937</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>1.256502</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>-1.290045</td>\n",
       "      <td>-1.231425</td>\n",
       "      <td>5.278051</td>\n",
       "      <td>1.752731</td>\n",
       "      <td>-1.690252</td>\n",
       "      <td>-0.847034</td>\n",
       "      <td>0.700464</td>\n",
       "      <td>-0.556565</td>\n",
       "      <td>-0.530960</td>\n",
       "      <td>-2.007095</td>\n",
       "      <td>-1.445137</td>\n",
       "      <td>1.137029</td>\n",
       "      <td>0.735991</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>1.833478</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>2.126637</td>\n",
       "      <td>-1.029467</td>\n",
       "      <td>-0.769431</td>\n",
       "      <td>-1.297839</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.199032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-14</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>Washington Wizards</td>\n",
       "      <td>0021300007</td>\n",
       "      <td>2013-10-30</td>\n",
       "      <td>WAS @ DET</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.958922</td>\n",
       "      <td>-0.393311</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>-0.635104</td>\n",
       "      <td>1.076533</td>\n",
       "      <td>1.256502</td>\n",
       "      <td>0.712450</td>\n",
       "      <td>-1.576556</td>\n",
       "      <td>-0.889718</td>\n",
       "      <td>-0.137041</td>\n",
       "      <td>-0.888676</td>\n",
       "      <td>-0.739883</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>2.286753</td>\n",
       "      <td>-0.469531</td>\n",
       "      <td>-0.770522</td>\n",
       "      <td>-0.110245</td>\n",
       "      <td>-0.453341</td>\n",
       "      <td>0.516310</td>\n",
       "      <td>0.512585</td>\n",
       "      <td>-0.500828</td>\n",
       "      <td>-0.777651</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>-0.990810</td>\n",
       "      <td>1.045528</td>\n",
       "      <td>-0.712572</td>\n",
       "      <td>0.988173</td>\n",
       "      <td>-1.708937</td>\n",
       "      <td>-0.312102</td>\n",
       "      <td>0.385204</td>\n",
       "      <td>-0.934656</td>\n",
       "      <td>-1.023665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26673</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612766</td>\n",
       "      <td>CHA</td>\n",
       "      <td>Charlotte Hornets</td>\n",
       "      <td>0022300484</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>CHA @ CHI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.581767</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>0.441333</td>\n",
       "      <td>-1.430537</td>\n",
       "      <td>-1.484801</td>\n",
       "      <td>0.448450</td>\n",
       "      <td>-0.658792</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>-0.713543</td>\n",
       "      <td>-0.203176</td>\n",
       "      <td>-1.542274</td>\n",
       "      <td>-0.281618</td>\n",
       "      <td>-0.052662</td>\n",
       "      <td>-1.300038</td>\n",
       "      <td>-0.910616</td>\n",
       "      <td>-1.028633</td>\n",
       "      <td>-0.996675</td>\n",
       "      <td>0.430480</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>-1.143789</td>\n",
       "      <td>-0.972063</td>\n",
       "      <td>-1.025825</td>\n",
       "      <td>-1.514670</td>\n",
       "      <td>0.620448</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>-0.932400</td>\n",
       "      <td>-0.998095</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26674</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>NOP</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>0022300486</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>NOP vs. LAC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.524655</td>\n",
       "      <td>0.715610</td>\n",
       "      <td>0.285284</td>\n",
       "      <td>-0.156687</td>\n",
       "      <td>-0.093433</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>0.976450</td>\n",
       "      <td>-0.842345</td>\n",
       "      <td>-0.134496</td>\n",
       "      <td>-0.329209</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>0.062508</td>\n",
       "      <td>-1.298793</td>\n",
       "      <td>-0.754486</td>\n",
       "      <td>-0.998035</td>\n",
       "      <td>-1.120757</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>-0.712071</td>\n",
       "      <td>0.722302</td>\n",
       "      <td>0.754066</td>\n",
       "      <td>-1.218237</td>\n",
       "      <td>-1.180363</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-1.241352</td>\n",
       "      <td>-1.221566</td>\n",
       "      <td>-0.248569</td>\n",
       "      <td>0.174985</td>\n",
       "      <td>-0.738266</td>\n",
       "      <td>-0.540766</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>-1.411359</td>\n",
       "      <td>0.810381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26675</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>LAC</td>\n",
       "      <td>LA Clippers</td>\n",
       "      <td>0022300486</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>LAC @ NOP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.770345</td>\n",
       "      <td>-1.169557</td>\n",
       "      <td>1.016748</td>\n",
       "      <td>0.680541</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>1.176736</td>\n",
       "      <td>0.922815</td>\n",
       "      <td>0.823795</td>\n",
       "      <td>-0.545926</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>0.226969</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>0.209974</td>\n",
       "      <td>1.120745</td>\n",
       "      <td>0.722311</td>\n",
       "      <td>0.754069</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>-0.712069</td>\n",
       "      <td>1.218245</td>\n",
       "      <td>1.180363</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>1.241289</td>\n",
       "      <td>-0.371406</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>-1.451391</td>\n",
       "      <td>-0.641199</td>\n",
       "      <td>0.373890</td>\n",
       "      <td>0.946218</td>\n",
       "      <td>-1.173008</td>\n",
       "      <td>0.810381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26676</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>MIN</td>\n",
       "      <td>Minnesota Timberwolves</td>\n",
       "      <td>0022300485</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>MIN @ HOU</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549699</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>0.321729</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.343549</td>\n",
       "      <td>1.727394</td>\n",
       "      <td>1.224904</td>\n",
       "      <td>1.400297</td>\n",
       "      <td>1.510572</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>-0.027325</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>1.040480</td>\n",
       "      <td>1.891262</td>\n",
       "      <td>1.057051</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>-1.432033</td>\n",
       "      <td>-1.238153</td>\n",
       "      <td>1.962725</td>\n",
       "      <td>1.708055</td>\n",
       "      <td>0.519677</td>\n",
       "      <td>1.958749</td>\n",
       "      <td>-1.079873</td>\n",
       "      <td>1.143440</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>1.397211</td>\n",
       "      <td>0.831219</td>\n",
       "      <td>1.226725</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>-1.023665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26677</th>\n",
       "      <td>2023-24</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>POR</td>\n",
       "      <td>Portland Trail Blazers</td>\n",
       "      <td>0022300487</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>POR @ DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.581767</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.529105</td>\n",
       "      <td>1.158958</td>\n",
       "      <td>-0.929123</td>\n",
       "      <td>-0.799476</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-0.291687</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>0.631628</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>-0.739883</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>-1.222369</td>\n",
       "      <td>-0.394031</td>\n",
       "      <td>-2.521696</td>\n",
       "      <td>-1.294708</td>\n",
       "      <td>-1.281279</td>\n",
       "      <td>1.657850</td>\n",
       "      <td>1.564752</td>\n",
       "      <td>-2.328189</td>\n",
       "      <td>-2.291292</td>\n",
       "      <td>1.721734</td>\n",
       "      <td>-1.708271</td>\n",
       "      <td>-0.513099</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>0.825536</td>\n",
       "      <td>-0.252930</td>\n",
       "      <td>0.145226</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>-0.934656</td>\n",
       "      <td>-0.412316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23722 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SEASON     TEAM_ID TEAM_ABBREVIATION               TEAM_NAME  \\\n",
       "2      2013-14  1610612746               LAC    Los Angeles Clippers   \n",
       "3      2013-14  1610612747               LAL      Los Angeles Lakers   \n",
       "4      2013-14  1610612753               ORL           Orlando Magic   \n",
       "5      2013-14  1610612754               IND          Indiana Pacers   \n",
       "6      2013-14  1610612764               WAS      Washington Wizards   \n",
       "...        ...         ...               ...                     ...   \n",
       "26673  2023-24  1610612766               CHA       Charlotte Hornets   \n",
       "26674  2023-24  1610612740               NOP    New Orleans Pelicans   \n",
       "26675  2023-24  1610612746               LAC             LA Clippers   \n",
       "26676  2023-24  1610612750               MIN  Minnesota Timberwolves   \n",
       "26677  2023-24  1610612757               POR  Portland Trail Blazers   \n",
       "\n",
       "          GAME_ID  GAME_DATE      MATCHUP  HOME_GAME  WL      FG2M      FG2A  \\\n",
       "2      0021300003 2013-10-29    LAC @ LAL          0   0  0.738276  0.604718   \n",
       "3      0021300003 2013-10-29  LAL vs. LAC          1   1 -0.204612  0.826502   \n",
       "4      0021300001 2013-10-29    ORL @ IND          0   0 -0.393189  1.935424   \n",
       "5      0021300001 2013-10-29  IND vs. ORL          1   1 -0.393189 -0.282419   \n",
       "6      0021300007 2013-10-30    WAS @ DET          0   0 -0.958922 -0.393311   \n",
       "...           ...        ...          ...        ...  ..       ...       ...   \n",
       "26673  0022300484 2024-01-05    CHA @ CHI          0   0 -0.581767 -0.171527   \n",
       "26674  0022300486 2024-01-05  NOP vs. LAC          1   0 -1.524655  0.715610   \n",
       "26675  0022300486 2024-01-05    LAC @ NOP          0   1 -0.770345 -1.169557   \n",
       "26676  0022300485 2024-01-05    MIN @ HOU          0   1  0.549699 -0.171527   \n",
       "26677  0022300487 2024-01-05    POR @ DAL          0   0 -0.581767 -0.171527   \n",
       "\n",
       "           FG3M      FG3A       FTM       FTA      OREB      DREB       REB  \\\n",
       "2     -0.690002 -1.113520 -0.761985  0.022915 -0.079549 -0.658792 -0.587629   \n",
       "3      0.772927 -0.156687  0.073705  0.708241  2.032450  0.075419  1.224904   \n",
       "4     -0.446180 -1.352728 -1.931951 -1.758932  0.712450 -1.393003 -0.738674   \n",
       "5     -0.933823 -1.591937  0.742257  1.256502 -0.079549  0.075419  0.016549   \n",
       "6     -0.202359 -0.635104  1.076533  1.256502  0.712450 -1.576556 -0.889718   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "26673 -0.202359  0.441333 -1.430537 -1.484801  0.448450 -0.658792 -0.285540   \n",
       "26674  0.285284 -0.156687 -0.093433  0.022915  0.976450 -0.842345 -0.134496   \n",
       "26675  1.016748  0.680541 -0.260571 -0.388280 -0.079549  1.176736  0.922815   \n",
       "26676  0.772927  0.321729 -0.260571 -0.388280 -0.343549  1.727394  1.224904   \n",
       "26677  0.529105  1.158958 -0.929123 -0.799476 -0.079549 -0.291687 -0.285540   \n",
       "\n",
       "            AST       STL       BLK       TOV        PF       PTS  PLUS_MINUS  \\\n",
       "2      0.631628  1.167823 -0.338687  0.481263  0.181279 -0.394031   -0.910616   \n",
       "3     -0.137041  0.139573  0.463704  1.244144  0.649162  0.587477    0.910605   \n",
       "4     -1.290045  0.825073  0.463704  1.244144  1.350987 -1.602040   -0.700475   \n",
       "5     -1.290045 -1.231425  5.278051  1.752731 -1.690252 -0.847034    0.700464   \n",
       "6     -0.137041 -0.888676 -0.739883  0.735556  2.286753 -0.469531   -0.770522   \n",
       "...         ...       ...       ...       ...       ...       ...         ...   \n",
       "26673 -0.713543 -0.203176 -1.542274 -0.281618 -0.052662 -1.300038   -0.910616   \n",
       "26674 -0.329209  0.482323  0.062508 -1.298793 -0.754486 -0.998035   -1.120757   \n",
       "26675  0.823795 -0.545926  0.864899  0.226969 -0.520545  0.209974    1.120745   \n",
       "26676  1.400297  1.510572  0.864899 -0.027325 -0.520545  1.040480    1.891262   \n",
       "26677  0.631628  0.482323 -0.739883  1.244144 -1.222369 -0.394031   -2.521696   \n",
       "\n",
       "       E_OFF_RATING  OFF_RATING  E_DEF_RATING  DEF_RATING  E_NET_RATING  \\\n",
       "2         -0.307656   -0.367097      0.138657    0.676447     -0.351932   \n",
       "3          0.138663    0.676450     -0.307659   -0.367096      0.351940   \n",
       "4         -2.007102   -1.445142     -0.556566   -0.530958     -1.137021   \n",
       "5         -0.556565   -0.530960     -2.007095   -1.445137      1.137029   \n",
       "6         -0.110245   -0.453341      0.516310    0.512585     -0.500828   \n",
       "...             ...         ...           ...         ...           ...   \n",
       "26673     -1.028633   -0.996675      0.430480    0.210733     -1.143789   \n",
       "26674     -0.831223   -0.712071      0.722302    0.754066     -1.218237   \n",
       "26675      0.722311    0.754069     -0.831223   -0.712069      1.218245   \n",
       "26676      1.057051    0.883434     -1.432033   -1.238153      1.962725   \n",
       "26677     -1.294708   -1.281279      1.657850    1.564752     -2.328189   \n",
       "\n",
       "       NET_RATING      POSS       PIE  PTS_2PT_MR    PTS_FB  PTS_OFF_TOV  \\\n",
       "2       -0.840140 -0.167213 -0.034196    0.903834  0.834105     1.476086   \n",
       "3        0.840141  0.004510  0.034133    0.337061 -0.093901     1.801361   \n",
       "4       -0.735991 -0.854102 -1.833541    1.187221 -0.403236     0.662898   \n",
       "5        0.735991 -0.854102  1.833478    0.903834 -0.093901     2.126637   \n",
       "6       -0.777651 -0.167213 -0.990810    1.045528 -0.712572     0.988173   \n",
       "...           ...       ...       ...         ...       ...          ...   \n",
       "26673   -0.972063 -1.025825 -1.514670    0.620448 -0.403236     0.012348   \n",
       "26674   -1.180363 -0.854102 -1.241352   -1.221566 -0.248569     0.174985   \n",
       "26675    1.180363 -0.854102  1.241289   -0.371406 -0.093901    -1.451391   \n",
       "26676    1.708055  0.519677  1.958749   -1.079873  1.143440     0.337623   \n",
       "26677   -2.291292  1.721734 -1.708271   -0.513099 -0.093901     0.825536   \n",
       "\n",
       "       PTS_PAINT   AST_2PM   AST_3PM  UAST_2PM  UAST_3PM  \n",
       "2       0.135338  1.059883 -0.456318 -0.219602 -0.412316  \n",
       "3      -0.447064 -0.540766  0.665711  0.257100  0.199032  \n",
       "4      -1.126534 -1.226759 -0.456318  0.733803 -0.412316  \n",
       "5      -1.029467 -0.769431 -1.297839  0.257100  0.199032  \n",
       "6      -1.708937 -0.312102  0.385204 -0.934656 -1.023665  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "26673  -0.932400 -0.998095  0.104697  0.257100 -0.412316  \n",
       "26674  -0.738266 -0.540766  0.104697 -1.411359  0.810381  \n",
       "26675  -0.641199  0.373890  0.946218 -1.173008  0.810381  \n",
       "26676   1.397211  0.831219  1.226725  0.018749 -1.023665  \n",
       "26677  -0.252930  0.145226  0.665711 -0.934656 -0.412316  \n",
       "\n",
       "[23722 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Input Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(data['TEAM_ABBREVIATION'])\n",
    "\n",
    "data['TEAM_ABBREVIATION'] = encoder.transform(data['TEAM_ABBREVIATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AST</th>\n",
       "      <th>AST_2PM</th>\n",
       "      <th>AST_3PM</th>\n",
       "      <th>BLK</th>\n",
       "      <th>DEF_RATING</th>\n",
       "      <th>DREB</th>\n",
       "      <th>E_DEF_RATING</th>\n",
       "      <th>E_NET_RATING</th>\n",
       "      <th>E_OFF_RATING</th>\n",
       "      <th>FG2A</th>\n",
       "      <th>FG2M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>HOME_GAME</th>\n",
       "      <th>NET_RATING</th>\n",
       "      <th>OFF_RATING</th>\n",
       "      <th>OREB</th>\n",
       "      <th>PF</th>\n",
       "      <th>PIE</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>POSS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PTS_2PT_MR</th>\n",
       "      <th>PTS_FB</th>\n",
       "      <th>PTS_OFF_TOV</th>\n",
       "      <th>PTS_PAINT</th>\n",
       "      <th>REB</th>\n",
       "      <th>STL</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>TOV</th>\n",
       "      <th>UAST_2PM</th>\n",
       "      <th>UAST_3PM</th>\n",
       "      <th>WL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.631628</td>\n",
       "      <td>1.059883</td>\n",
       "      <td>-0.456318</td>\n",
       "      <td>-0.338687</td>\n",
       "      <td>0.676447</td>\n",
       "      <td>-0.658792</td>\n",
       "      <td>0.138657</td>\n",
       "      <td>-0.351932</td>\n",
       "      <td>-0.307656</td>\n",
       "      <td>0.604718</td>\n",
       "      <td>0.738276</td>\n",
       "      <td>-1.113520</td>\n",
       "      <td>-0.690002</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>-0.761985</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.840140</td>\n",
       "      <td>-0.367097</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>0.181279</td>\n",
       "      <td>-0.034196</td>\n",
       "      <td>-0.910616</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>-0.394031</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>0.834105</td>\n",
       "      <td>1.476086</td>\n",
       "      <td>0.135338</td>\n",
       "      <td>-0.587629</td>\n",
       "      <td>1.167823</td>\n",
       "      <td>12</td>\n",
       "      <td>0.481263</td>\n",
       "      <td>-0.219602</td>\n",
       "      <td>-0.412316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.137041</td>\n",
       "      <td>-0.540766</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>0.463704</td>\n",
       "      <td>-0.367096</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>-0.307659</td>\n",
       "      <td>0.351940</td>\n",
       "      <td>0.138663</td>\n",
       "      <td>0.826502</td>\n",
       "      <td>-0.204612</td>\n",
       "      <td>-0.156687</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>0.708241</td>\n",
       "      <td>0.073705</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840141</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>2.032450</td>\n",
       "      <td>0.649162</td>\n",
       "      <td>0.034133</td>\n",
       "      <td>0.910605</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.587477</td>\n",
       "      <td>0.337061</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>1.801361</td>\n",
       "      <td>-0.447064</td>\n",
       "      <td>1.224904</td>\n",
       "      <td>0.139573</td>\n",
       "      <td>13</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.199032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.290045</td>\n",
       "      <td>-1.226759</td>\n",
       "      <td>-0.456318</td>\n",
       "      <td>0.463704</td>\n",
       "      <td>-0.530958</td>\n",
       "      <td>-1.393003</td>\n",
       "      <td>-0.556566</td>\n",
       "      <td>-1.137021</td>\n",
       "      <td>-2.007102</td>\n",
       "      <td>1.935424</td>\n",
       "      <td>-0.393189</td>\n",
       "      <td>-1.352728</td>\n",
       "      <td>-0.446180</td>\n",
       "      <td>-1.758932</td>\n",
       "      <td>-1.931951</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.735991</td>\n",
       "      <td>-1.445142</td>\n",
       "      <td>0.712450</td>\n",
       "      <td>1.350987</td>\n",
       "      <td>-1.833541</td>\n",
       "      <td>-0.700475</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-1.602040</td>\n",
       "      <td>1.187221</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.662898</td>\n",
       "      <td>-1.126534</td>\n",
       "      <td>-0.738674</td>\n",
       "      <td>0.825073</td>\n",
       "      <td>21</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>0.733803</td>\n",
       "      <td>-0.412316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.290045</td>\n",
       "      <td>-0.769431</td>\n",
       "      <td>-1.297839</td>\n",
       "      <td>5.278051</td>\n",
       "      <td>-1.445137</td>\n",
       "      <td>0.075419</td>\n",
       "      <td>-2.007095</td>\n",
       "      <td>1.137029</td>\n",
       "      <td>-0.556565</td>\n",
       "      <td>-0.282419</td>\n",
       "      <td>-0.393189</td>\n",
       "      <td>-1.591937</td>\n",
       "      <td>-0.933823</td>\n",
       "      <td>1.256502</td>\n",
       "      <td>0.742257</td>\n",
       "      <td>1</td>\n",
       "      <td>0.735991</td>\n",
       "      <td>-0.530960</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-1.690252</td>\n",
       "      <td>1.833478</td>\n",
       "      <td>0.700464</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-0.847034</td>\n",
       "      <td>0.903834</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>2.126637</td>\n",
       "      <td>-1.029467</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>-1.231425</td>\n",
       "      <td>11</td>\n",
       "      <td>1.752731</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.199032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.137041</td>\n",
       "      <td>-0.312102</td>\n",
       "      <td>0.385204</td>\n",
       "      <td>-0.739883</td>\n",
       "      <td>0.512585</td>\n",
       "      <td>-1.576556</td>\n",
       "      <td>0.516310</td>\n",
       "      <td>-0.500828</td>\n",
       "      <td>-0.110245</td>\n",
       "      <td>-0.393311</td>\n",
       "      <td>-0.958922</td>\n",
       "      <td>-0.635104</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>1.256502</td>\n",
       "      <td>1.076533</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.777651</td>\n",
       "      <td>-0.453341</td>\n",
       "      <td>0.712450</td>\n",
       "      <td>2.286753</td>\n",
       "      <td>-0.990810</td>\n",
       "      <td>-0.770522</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>-0.469531</td>\n",
       "      <td>1.045528</td>\n",
       "      <td>-0.712572</td>\n",
       "      <td>0.988173</td>\n",
       "      <td>-1.708937</td>\n",
       "      <td>-0.889718</td>\n",
       "      <td>-0.888676</td>\n",
       "      <td>29</td>\n",
       "      <td>0.735556</td>\n",
       "      <td>-0.934656</td>\n",
       "      <td>-1.023665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26673</th>\n",
       "      <td>-0.713543</td>\n",
       "      <td>-0.998095</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>-1.542274</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>-0.658792</td>\n",
       "      <td>0.430480</td>\n",
       "      <td>-1.143789</td>\n",
       "      <td>-1.028633</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>-0.581767</td>\n",
       "      <td>0.441333</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>-1.484801</td>\n",
       "      <td>-1.430537</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.972063</td>\n",
       "      <td>-0.996675</td>\n",
       "      <td>0.448450</td>\n",
       "      <td>-0.052662</td>\n",
       "      <td>-1.514670</td>\n",
       "      <td>-0.910616</td>\n",
       "      <td>-1.025825</td>\n",
       "      <td>-1.300038</td>\n",
       "      <td>0.620448</td>\n",
       "      <td>-0.403236</td>\n",
       "      <td>0.012348</td>\n",
       "      <td>-0.932400</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>-0.203176</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.281618</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>-0.412316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26674</th>\n",
       "      <td>-0.329209</td>\n",
       "      <td>-0.540766</td>\n",
       "      <td>0.104697</td>\n",
       "      <td>0.062508</td>\n",
       "      <td>0.754066</td>\n",
       "      <td>-0.842345</td>\n",
       "      <td>0.722302</td>\n",
       "      <td>-1.218237</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>0.715610</td>\n",
       "      <td>-1.524655</td>\n",
       "      <td>-0.156687</td>\n",
       "      <td>0.285284</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>-0.093433</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.180363</td>\n",
       "      <td>-0.712071</td>\n",
       "      <td>0.976450</td>\n",
       "      <td>-0.754486</td>\n",
       "      <td>-1.241352</td>\n",
       "      <td>-1.120757</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>-0.998035</td>\n",
       "      <td>-1.221566</td>\n",
       "      <td>-0.248569</td>\n",
       "      <td>0.174985</td>\n",
       "      <td>-0.738266</td>\n",
       "      <td>-0.134496</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.298793</td>\n",
       "      <td>-1.411359</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26675</th>\n",
       "      <td>0.823795</td>\n",
       "      <td>0.373890</td>\n",
       "      <td>0.946218</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>-0.712069</td>\n",
       "      <td>1.176736</td>\n",
       "      <td>-0.831223</td>\n",
       "      <td>1.218245</td>\n",
       "      <td>0.722311</td>\n",
       "      <td>-1.169557</td>\n",
       "      <td>-0.770345</td>\n",
       "      <td>0.680541</td>\n",
       "      <td>1.016748</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>0</td>\n",
       "      <td>1.180363</td>\n",
       "      <td>0.754069</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>1.241289</td>\n",
       "      <td>1.120745</td>\n",
       "      <td>-0.854102</td>\n",
       "      <td>0.209974</td>\n",
       "      <td>-0.371406</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>-1.451391</td>\n",
       "      <td>-0.641199</td>\n",
       "      <td>0.922815</td>\n",
       "      <td>-0.545926</td>\n",
       "      <td>12</td>\n",
       "      <td>0.226969</td>\n",
       "      <td>-1.173008</td>\n",
       "      <td>0.810381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26676</th>\n",
       "      <td>1.400297</td>\n",
       "      <td>0.831219</td>\n",
       "      <td>1.226725</td>\n",
       "      <td>0.864899</td>\n",
       "      <td>-1.238153</td>\n",
       "      <td>1.727394</td>\n",
       "      <td>-1.432033</td>\n",
       "      <td>1.962725</td>\n",
       "      <td>1.057051</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>0.549699</td>\n",
       "      <td>0.321729</td>\n",
       "      <td>0.772927</td>\n",
       "      <td>-0.388280</td>\n",
       "      <td>-0.260571</td>\n",
       "      <td>0</td>\n",
       "      <td>1.708055</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>-0.343549</td>\n",
       "      <td>-0.520545</td>\n",
       "      <td>1.958749</td>\n",
       "      <td>1.891262</td>\n",
       "      <td>0.519677</td>\n",
       "      <td>1.040480</td>\n",
       "      <td>-1.079873</td>\n",
       "      <td>1.143440</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>1.397211</td>\n",
       "      <td>1.224904</td>\n",
       "      <td>1.510572</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.027325</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>-1.023665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26677</th>\n",
       "      <td>0.631628</td>\n",
       "      <td>0.145226</td>\n",
       "      <td>0.665711</td>\n",
       "      <td>-0.739883</td>\n",
       "      <td>1.564752</td>\n",
       "      <td>-0.291687</td>\n",
       "      <td>1.657850</td>\n",
       "      <td>-2.328189</td>\n",
       "      <td>-1.294708</td>\n",
       "      <td>-0.171527</td>\n",
       "      <td>-0.581767</td>\n",
       "      <td>1.158958</td>\n",
       "      <td>0.529105</td>\n",
       "      <td>-0.799476</td>\n",
       "      <td>-0.929123</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.291292</td>\n",
       "      <td>-1.281279</td>\n",
       "      <td>-0.079549</td>\n",
       "      <td>-1.222369</td>\n",
       "      <td>-1.708271</td>\n",
       "      <td>-2.521696</td>\n",
       "      <td>1.721734</td>\n",
       "      <td>-0.394031</td>\n",
       "      <td>-0.513099</td>\n",
       "      <td>-0.093901</td>\n",
       "      <td>0.825536</td>\n",
       "      <td>-0.252930</td>\n",
       "      <td>-0.285540</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>24</td>\n",
       "      <td>1.244144</td>\n",
       "      <td>-0.934656</td>\n",
       "      <td>-0.412316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23722 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AST   AST_2PM   AST_3PM       BLK  DEF_RATING      DREB  \\\n",
       "2      0.631628  1.059883 -0.456318 -0.338687    0.676447 -0.658792   \n",
       "3     -0.137041 -0.540766  0.665711  0.463704   -0.367096  0.075419   \n",
       "4     -1.290045 -1.226759 -0.456318  0.463704   -0.530958 -1.393003   \n",
       "5     -1.290045 -0.769431 -1.297839  5.278051   -1.445137  0.075419   \n",
       "6     -0.137041 -0.312102  0.385204 -0.739883    0.512585 -1.576556   \n",
       "...         ...       ...       ...       ...         ...       ...   \n",
       "26673 -0.713543 -0.998095  0.104697 -1.542274    0.210733 -0.658792   \n",
       "26674 -0.329209 -0.540766  0.104697  0.062508    0.754066 -0.842345   \n",
       "26675  0.823795  0.373890  0.946218  0.864899   -0.712069  1.176736   \n",
       "26676  1.400297  0.831219  1.226725  0.864899   -1.238153  1.727394   \n",
       "26677  0.631628  0.145226  0.665711 -0.739883    1.564752 -0.291687   \n",
       "\n",
       "       E_DEF_RATING  E_NET_RATING  E_OFF_RATING      FG2A      FG2M      FG3A  \\\n",
       "2          0.138657     -0.351932     -0.307656  0.604718  0.738276 -1.113520   \n",
       "3         -0.307659      0.351940      0.138663  0.826502 -0.204612 -0.156687   \n",
       "4         -0.556566     -1.137021     -2.007102  1.935424 -0.393189 -1.352728   \n",
       "5         -2.007095      1.137029     -0.556565 -0.282419 -0.393189 -1.591937   \n",
       "6          0.516310     -0.500828     -0.110245 -0.393311 -0.958922 -0.635104   \n",
       "...             ...           ...           ...       ...       ...       ...   \n",
       "26673      0.430480     -1.143789     -1.028633 -0.171527 -0.581767  0.441333   \n",
       "26674      0.722302     -1.218237     -0.831223  0.715610 -1.524655 -0.156687   \n",
       "26675     -0.831223      1.218245      0.722311 -1.169557 -0.770345  0.680541   \n",
       "26676     -1.432033      1.962725      1.057051 -0.171527  0.549699  0.321729   \n",
       "26677      1.657850     -2.328189     -1.294708 -0.171527 -0.581767  1.158958   \n",
       "\n",
       "           FG3M       FTA       FTM  HOME_GAME  NET_RATING  OFF_RATING  \\\n",
       "2     -0.690002  0.022915 -0.761985          0   -0.840140   -0.367097   \n",
       "3      0.772927  0.708241  0.073705          1    0.840141    0.676450   \n",
       "4     -0.446180 -1.758932 -1.931951          0   -0.735991   -1.445142   \n",
       "5     -0.933823  1.256502  0.742257          1    0.735991   -0.530960   \n",
       "6     -0.202359  1.256502  1.076533          0   -0.777651   -0.453341   \n",
       "...         ...       ...       ...        ...         ...         ...   \n",
       "26673 -0.202359 -1.484801 -1.430537          0   -0.972063   -0.996675   \n",
       "26674  0.285284  0.022915 -0.093433          1   -1.180363   -0.712071   \n",
       "26675  1.016748 -0.388280 -0.260571          0    1.180363    0.754069   \n",
       "26676  0.772927 -0.388280 -0.260571          0    1.708055    0.883434   \n",
       "26677  0.529105 -0.799476 -0.929123          0   -2.291292   -1.281279   \n",
       "\n",
       "           OREB        PF       PIE  PLUS_MINUS      POSS       PTS  \\\n",
       "2     -0.079549  0.181279 -0.034196   -0.910616 -0.167213 -0.394031   \n",
       "3      2.032450  0.649162  0.034133    0.910605  0.004510  0.587477   \n",
       "4      0.712450  1.350987 -1.833541   -0.700475 -0.854102 -1.602040   \n",
       "5     -0.079549 -1.690252  1.833478    0.700464 -0.854102 -0.847034   \n",
       "6      0.712450  2.286753 -0.990810   -0.770522 -0.167213 -0.469531   \n",
       "...         ...       ...       ...         ...       ...       ...   \n",
       "26673  0.448450 -0.052662 -1.514670   -0.910616 -1.025825 -1.300038   \n",
       "26674  0.976450 -0.754486 -1.241352   -1.120757 -0.854102 -0.998035   \n",
       "26675 -0.079549 -0.520545  1.241289    1.120745 -0.854102  0.209974   \n",
       "26676 -0.343549 -0.520545  1.958749    1.891262  0.519677  1.040480   \n",
       "26677 -0.079549 -1.222369 -1.708271   -2.521696  1.721734 -0.394031   \n",
       "\n",
       "       PTS_2PT_MR    PTS_FB  PTS_OFF_TOV  PTS_PAINT       REB       STL  \\\n",
       "2        0.903834  0.834105     1.476086   0.135338 -0.587629  1.167823   \n",
       "3        0.337061 -0.093901     1.801361  -0.447064  1.224904  0.139573   \n",
       "4        1.187221 -0.403236     0.662898  -1.126534 -0.738674  0.825073   \n",
       "5        0.903834 -0.093901     2.126637  -1.029467  0.016549 -1.231425   \n",
       "6        1.045528 -0.712572     0.988173  -1.708937 -0.889718 -0.888676   \n",
       "...           ...       ...          ...        ...       ...       ...   \n",
       "26673    0.620448 -0.403236     0.012348  -0.932400 -0.285540 -0.203176   \n",
       "26674   -1.221566 -0.248569     0.174985  -0.738266 -0.134496  0.482323   \n",
       "26675   -0.371406 -0.093901    -1.451391  -0.641199  0.922815 -0.545926   \n",
       "26676   -1.079873  1.143440     0.337623   1.397211  1.224904  1.510572   \n",
       "26677   -0.513099 -0.093901     0.825536  -0.252930 -0.285540  0.482323   \n",
       "\n",
       "       TEAM_ABBREVIATION       TOV  UAST_2PM  UAST_3PM  WL  \n",
       "2                     12  0.481263 -0.219602 -0.412316   0  \n",
       "3                     13  1.244144  0.257100  0.199032   1  \n",
       "4                     21  1.244144  0.733803 -0.412316   0  \n",
       "5                     11  1.752731  0.257100  0.199032   1  \n",
       "6                     29  0.735556 -0.934656 -1.023665   0  \n",
       "...                  ...       ...       ...       ...  ..  \n",
       "26673                  3 -0.281618  0.257100 -0.412316   0  \n",
       "26674                 18 -1.298793 -1.411359  0.810381   0  \n",
       "26675                 12  0.226969 -1.173008  0.810381   1  \n",
       "26676                 17 -0.027325  0.018749 -1.023665   1  \n",
       "26677                 24  1.244144 -0.934656 -0.412316   0  \n",
       "\n",
       "[23722 rows x 35 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = ['SEASON',\"TEAM_ID\",'TEAM_NAME','GAME_ID','GAME_DATE','MATCHUP']\n",
    "data_clean = data[data.columns.difference(filter)]\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "y_list = []\n",
    "window_size = 10\n",
    "\n",
    "for i in range(len(data_clean['TEAM_ABBREVIATION'].unique())):\n",
    "    team = data_clean.loc[data_clean['TEAM_ABBREVIATION'] == i]\n",
    "    team_label = team['WL'].copy()\n",
    "    team = team.drop('WL',axis=1)\n",
    "\n",
    "    team_np = team.to_numpy()\n",
    "    team_label = team_label.to_numpy()\n",
    "\n",
    "    #temp_X = []\n",
    "    #temp_y = []\n",
    "    \n",
    "    for i in range(len(team_np)-window_size):        \n",
    "      row = [a for a in team_np[i:i+window_size]]\n",
    "      X_list.append(row)\n",
    "\n",
    "      label = team_label[i+window_size]\n",
    "      y_list.append(label)\n",
    "\n",
    "X_list = np.array(X_list)\n",
    "y_list = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.05512596, -0.31210227,  0.3852037 , ..., -0.28161824,\n",
       "         -0.45795375, -1.02366523],\n",
       "        [ 0.43946043,  0.83121882, -0.17581068, ..., -0.02732461,\n",
       "         -0.45795375, -1.02366523],\n",
       "        [ 1.40029662,  2.20320412, -0.45631787, ..., -0.79020549,\n",
       "         -0.93465649, -0.41231641],\n",
       "        ...,\n",
       "        [-0.13704128,  1.05988304, -1.29783944, ...,  2.00702438,\n",
       "         -0.45795375, -1.02366523],\n",
       "        [-0.71354299, -0.54076649, -0.17581068, ...,  0.22696901,\n",
       "          0.49545174, -1.02366523],\n",
       "        [-0.13704128,  0.83121882, -1.01733225, ..., -1.29879273,\n",
       "         -0.45795375, -1.02366523]],\n",
       "\n",
       "       [[ 0.43946043,  0.83121882, -0.17581068, ..., -0.02732461,\n",
       "         -0.45795375, -1.02366523],\n",
       "        [ 1.40029662,  2.20320412, -0.45631787, ..., -0.79020549,\n",
       "         -0.93465649, -0.41231641],\n",
       "        [ 2.3611328 ,  3.57518943, -0.73682506, ..., -0.28161824,\n",
       "         -1.88806197, -1.02366523],\n",
       "        ...,\n",
       "        [-0.71354299, -0.54076649, -0.17581068, ...,  0.22696901,\n",
       "          0.49545174, -1.02366523],\n",
       "        [-0.13704128,  0.83121882, -1.01733225, ..., -1.29879273,\n",
       "         -0.45795375, -1.02366523],\n",
       "        [-0.52137575, -0.31210227, -0.17581068, ...,  0.98984989,\n",
       "         -0.93465649, -1.02366523]],\n",
       "\n",
       "       [[ 1.40029662,  2.20320412, -0.45631787, ..., -0.79020549,\n",
       "         -0.93465649, -0.41231641],\n",
       "        [ 2.3611328 ,  3.57518943, -0.73682506, ..., -0.28161824,\n",
       "         -1.88806197, -1.02366523],\n",
       "        [ 0.43946043,  0.6025546 ,  0.10469651, ..., -0.28161824,\n",
       "         -1.41135923, -0.41231641],\n",
       "        ...,\n",
       "        [-0.13704128,  0.83121882, -1.01733225, ..., -1.29879273,\n",
       "         -0.45795375, -1.02366523],\n",
       "        [-0.52137575, -0.31210227, -0.17581068, ...,  0.98984989,\n",
       "         -0.93465649, -1.02366523],\n",
       "        [-0.90571022,  0.14522617, -1.57834663, ...,  0.48126264,\n",
       "         -0.45795375, -1.02366523]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.52137575, -0.54076649, -0.17581068, ...,  2.00702438,\n",
       "          0.01874899, -1.02366523],\n",
       "        [ 0.82379491, -0.54076649,  1.50723246, ...,  0.22696901,\n",
       "         -0.93465649,  1.42173006],\n",
       "        [ 2.3611328 ,  2.20320412,  0.3852037 , ...,  1.24414351,\n",
       "          0.01874899,  0.19903242],\n",
       "        ...,\n",
       "        [ 0.63162767, -0.54076649,  1.50723246, ...,  1.49843714,\n",
       "          0.01874899,  0.19903242],\n",
       "        [ 0.2472932 ,  1.05988304, -1.01733225, ...,  0.73555626,\n",
       "          0.01874899,  0.81038124],\n",
       "        [ 0.82379491,  0.83121882,  0.3852037 , ..., -1.80737998,\n",
       "         -0.45795375,  1.42173006]],\n",
       "\n",
       "       [[ 0.82379491, -0.54076649,  1.50723246, ...,  0.22696901,\n",
       "         -0.93465649,  1.42173006],\n",
       "        [ 2.3611328 ,  2.20320412,  0.3852037 , ...,  1.24414351,\n",
       "          0.01874899,  0.19903242],\n",
       "        [ 0.05512596, -0.54076649,  0.66571089, ..., -1.04449911,\n",
       "         -0.21960238,  0.19903242],\n",
       "        ...,\n",
       "        [ 0.2472932 ,  1.05988304, -1.01733225, ...,  0.73555626,\n",
       "          0.01874899,  0.81038124],\n",
       "        [ 0.82379491,  0.83121882,  0.3852037 , ..., -1.80737998,\n",
       "         -0.45795375,  1.42173006],\n",
       "        [ 2.16896557,  1.74587569,  1.22672527, ..., -1.29879273,\n",
       "         -1.88806197,  0.81038124]],\n",
       "\n",
       "       [[ 2.3611328 ,  2.20320412,  0.3852037 , ...,  1.24414351,\n",
       "          0.01874899,  0.19903242],\n",
       "        [ 0.05512596, -0.54076649,  0.66571089, ..., -1.04449911,\n",
       "         -0.21960238,  0.19903242],\n",
       "        [ 0.43946043, -0.31210227,  0.94621808, ..., -0.53591186,\n",
       "         -0.21960238,  2.03307888],\n",
       "        ...,\n",
       "        [ 0.82379491,  0.83121882,  0.3852037 , ..., -1.80737998,\n",
       "         -0.45795375,  1.42173006],\n",
       "        [ 2.16896557,  1.74587569,  1.22672527, ..., -1.29879273,\n",
       "         -1.88806197,  0.81038124],\n",
       "        [-0.32920851, -0.54076649,  0.10469651, ..., -1.55308636,\n",
       "          0.73380311,  0.19903242]]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "window_size = 30\n",
    "\n",
    "X_total = []\n",
    "y_total = []\n",
    "\n",
    "team = data_clean\n",
    "team_label = team['WL']\n",
    "team_np = team.to_numpy()\n",
    "team_label = team_label.to_numpy()\n",
    "\n",
    "for i in range(len(team_np)-window_size):        \n",
    "    row = [a for a in team_np[i:i+window_size]]\n",
    "    X_total.append(row)\n",
    "    label = team_label[i+window_size]\n",
    "    y_total.append(label)\n",
    "\n",
    "X_total = np.array(X_total)\n",
    "y_total = np.array(y_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23422, 10, 35), (23422,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list.shape, y_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "X_train, X_test_temp, y_train, y_test_temp = train_test_split(X_list, y_list, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_temp, y_test_temp, test_size=test_ratio/(test_ratio + validation_ratio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 34)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                25344     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25873 (101.07 KB)\n",
      "Trainable params: 25873 (101.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, Accuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(InputLayer((10,34)))\n",
    "#model1.add(LSTM(256,input_shape=(30,35),return_sequences=True))\n",
    "#model1.add(LSTM(128, input_shape=(10,35), return_sequences=True))\n",
    "model1.add(LSTM(64))\n",
    "model1.add(Dense(8, 'tanh'))\n",
    "model1.add(Dense(1,'sigmoid'))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sigmoid'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"Dense(1,'sigmoid')\"\n",
    "\n",
    "test[test.find(\"'\")+1:test.find(\")\")-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(\"C:\\\\Users\\\\alexp\\\\src\\\\NBA_Models\\\\src\\\\models\\\\model1\", save_best_only=True)\n",
    "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=.00001), metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "543/549 [============================>.] - ETA: 0s - loss: 0.2721 - root_mean_squared_error: 0.5216INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 0.2720 - root_mean_squared_error: 0.5215 - val_loss: 0.2557 - val_root_mean_squared_error: 0.5057\n",
      "Epoch 2/200\n",
      "543/549 [============================>.] - ETA: 0s - loss: 0.2526 - root_mean_squared_error: 0.5026INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2526 - root_mean_squared_error: 0.5026 - val_loss: 0.2505 - val_root_mean_squared_error: 0.5005\n",
      "Epoch 3/200\n",
      "536/549 [============================>.] - ETA: 0s - loss: 0.2492 - root_mean_squared_error: 0.4992INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2492 - root_mean_squared_error: 0.4992 - val_loss: 0.2485 - val_root_mean_squared_error: 0.4985\n",
      "Epoch 4/200\n",
      "530/549 [===========================>..] - ETA: 0s - loss: 0.2475 - root_mean_squared_error: 0.4975INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2476 - root_mean_squared_error: 0.4976 - val_loss: 0.2475 - val_root_mean_squared_error: 0.4975\n",
      "Epoch 5/200\n",
      "545/549 [============================>.] - ETA: 0s - loss: 0.2467 - root_mean_squared_error: 0.4967INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2467 - root_mean_squared_error: 0.4967 - val_loss: 0.2468 - val_root_mean_squared_error: 0.4968\n",
      "Epoch 6/200\n",
      "535/549 [============================>.] - ETA: 0s - loss: 0.2459 - root_mean_squared_error: 0.4959INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2460 - root_mean_squared_error: 0.4959 - val_loss: 0.2463 - val_root_mean_squared_error: 0.4962\n",
      "Epoch 7/200\n",
      "548/549 [============================>.] - ETA: 0s - loss: 0.2454 - root_mean_squared_error: 0.4953INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 0.2454 - root_mean_squared_error: 0.4953 - val_loss: 0.2459 - val_root_mean_squared_error: 0.4959\n",
      "Epoch 8/200\n",
      "539/549 [============================>.] - ETA: 0s - loss: 0.2448 - root_mean_squared_error: 0.4948INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2448 - root_mean_squared_error: 0.4948 - val_loss: 0.2454 - val_root_mean_squared_error: 0.4953\n",
      "Epoch 9/200\n",
      "523/549 [===========================>..] - ETA: 0s - loss: 0.2445 - root_mean_squared_error: 0.4944INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2443 - root_mean_squared_error: 0.4943 - val_loss: 0.2450 - val_root_mean_squared_error: 0.4950\n",
      "Epoch 10/200\n",
      "535/549 [============================>.] - ETA: 0s - loss: 0.2437 - root_mean_squared_error: 0.4936INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2439 - root_mean_squared_error: 0.4939 - val_loss: 0.2448 - val_root_mean_squared_error: 0.4948\n",
      "Epoch 11/200\n",
      "534/549 [============================>.] - ETA: 0s - loss: 0.2435 - root_mean_squared_error: 0.4935INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2435 - root_mean_squared_error: 0.4935 - val_loss: 0.2445 - val_root_mean_squared_error: 0.4944\n",
      "Epoch 12/200\n",
      "523/549 [===========================>..] - ETA: 0s - loss: 0.2430 - root_mean_squared_error: 0.4929INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 0.2432 - root_mean_squared_error: 0.4931 - val_loss: 0.2442 - val_root_mean_squared_error: 0.4942\n",
      "Epoch 13/200\n",
      "542/549 [============================>.] - ETA: 0s - loss: 0.2428 - root_mean_squared_error: 0.4927INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2428 - root_mean_squared_error: 0.4928 - val_loss: 0.2439 - val_root_mean_squared_error: 0.4939\n",
      "Epoch 14/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2425 - root_mean_squared_error: 0.4924 - val_loss: 0.2440 - val_root_mean_squared_error: 0.4940\n",
      "Epoch 15/200\n",
      "547/549 [============================>.] - ETA: 0s - loss: 0.2422 - root_mean_squared_error: 0.4922INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2422 - root_mean_squared_error: 0.4922 - val_loss: 0.2436 - val_root_mean_squared_error: 0.4935\n",
      "Epoch 16/200\n",
      "531/549 [============================>.] - ETA: 0s - loss: 0.2420 - root_mean_squared_error: 0.4920INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2420 - root_mean_squared_error: 0.4919 - val_loss: 0.2434 - val_root_mean_squared_error: 0.4933\n",
      "Epoch 17/200\n",
      "527/549 [===========================>..] - ETA: 0s - loss: 0.2418 - root_mean_squared_error: 0.4918INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2417 - root_mean_squared_error: 0.4916 - val_loss: 0.2432 - val_root_mean_squared_error: 0.4932\n",
      "Epoch 18/200\n",
      "526/549 [===========================>..] - ETA: 0s - loss: 0.2413 - root_mean_squared_error: 0.4913INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 0.2415 - root_mean_squared_error: 0.4914 - val_loss: 0.2431 - val_root_mean_squared_error: 0.4930\n",
      "Epoch 19/200\n",
      "541/549 [============================>.] - ETA: 0s - loss: 0.2412 - root_mean_squared_error: 0.4912INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2413 - root_mean_squared_error: 0.4912 - val_loss: 0.2430 - val_root_mean_squared_error: 0.4929\n",
      "Epoch 20/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2410 - root_mean_squared_error: 0.4910 - val_loss: 0.2431 - val_root_mean_squared_error: 0.4930\n",
      "Epoch 21/200\n",
      "538/549 [============================>.] - ETA: 0s - loss: 0.2408 - root_mean_squared_error: 0.4907INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2409 - root_mean_squared_error: 0.4908 - val_loss: 0.2427 - val_root_mean_squared_error: 0.4927\n",
      "Epoch 22/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2407 - root_mean_squared_error: 0.4906 - val_loss: 0.2428 - val_root_mean_squared_error: 0.4927\n",
      "Epoch 23/200\n",
      "536/549 [============================>.] - ETA: 0s - loss: 0.2405 - root_mean_squared_error: 0.4904INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2406 - root_mean_squared_error: 0.4905 - val_loss: 0.2426 - val_root_mean_squared_error: 0.4925\n",
      "Epoch 24/200\n",
      "538/549 [============================>.] - ETA: 0s - loss: 0.2403 - root_mean_squared_error: 0.4902INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2404 - root_mean_squared_error: 0.4903 - val_loss: 0.2425 - val_root_mean_squared_error: 0.4924\n",
      "Epoch 25/200\n",
      "541/549 [============================>.] - ETA: 0s - loss: 0.2404 - root_mean_squared_error: 0.4903INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 0.2403 - root_mean_squared_error: 0.4902 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 26/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2401 - root_mean_squared_error: 0.4900 - val_loss: 0.2424 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 27/200\n",
      "523/549 [===========================>..] - ETA: 0s - loss: 0.2399 - root_mean_squared_error: 0.4898INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2400 - root_mean_squared_error: 0.4899 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 28/200\n",
      "538/549 [============================>.] - ETA: 0s - loss: 0.2399 - root_mean_squared_error: 0.4898INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2399 - root_mean_squared_error: 0.4898 - val_loss: 0.2422 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 29/200\n",
      "547/549 [============================>.] - ETA: 0s - loss: 0.2397 - root_mean_squared_error: 0.4896INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2398 - root_mean_squared_error: 0.4897 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 30/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2397 - root_mean_squared_error: 0.4896 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 31/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2396 - root_mean_squared_error: 0.4895 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 32/200\n",
      "537/549 [============================>.] - ETA: 0s - loss: 0.2394 - root_mean_squared_error: 0.4892INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 0.2395 - root_mean_squared_error: 0.4894 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 33/200\n",
      "535/549 [============================>.] - ETA: 0s - loss: 0.2394 - root_mean_squared_error: 0.4893INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2394 - root_mean_squared_error: 0.4893 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 34/200\n",
      "531/549 [============================>.] - ETA: 0s - loss: 0.2394 - root_mean_squared_error: 0.4893INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2393 - root_mean_squared_error: 0.4892 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 35/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2392 - root_mean_squared_error: 0.4891 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 36/200\n",
      "542/549 [============================>.] - ETA: 0s - loss: 0.2390 - root_mean_squared_error: 0.4889INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2391 - root_mean_squared_error: 0.4890 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 37/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2391 - root_mean_squared_error: 0.4889 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 38/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2390 - root_mean_squared_error: 0.4889 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 39/200\n",
      "539/549 [============================>.] - ETA: 0s - loss: 0.2389 - root_mean_squared_error: 0.4888INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2389 - root_mean_squared_error: 0.4888 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 40/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2388 - root_mean_squared_error: 0.4887 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 41/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2388 - root_mean_squared_error: 0.4887 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 42/200\n",
      "537/549 [============================>.] - ETA: 0s - loss: 0.2387 - root_mean_squared_error: 0.4885INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2387 - root_mean_squared_error: 0.4886 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 43/200\n",
      "543/549 [============================>.] - ETA: 0s - loss: 0.2387 - root_mean_squared_error: 0.4886INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 3s 5ms/step - loss: 0.2386 - root_mean_squared_error: 0.4885 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 44/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2386 - root_mean_squared_error: 0.4884 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 45/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2385 - root_mean_squared_error: 0.4884 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 46/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2384 - root_mean_squared_error: 0.4883 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 47/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2384 - root_mean_squared_error: 0.4882 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 48/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2383 - root_mean_squared_error: 0.4882 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 49/200\n",
      "539/549 [============================>.] - ETA: 0s - loss: 0.2382 - root_mean_squared_error: 0.4881INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2382 - root_mean_squared_error: 0.4881 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 50/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2382 - root_mean_squared_error: 0.4880 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 51/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2381 - root_mean_squared_error: 0.4880 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 52/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2380 - root_mean_squared_error: 0.4879 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 53/200\n",
      "537/549 [============================>.] - ETA: 0s - loss: 0.2380 - root_mean_squared_error: 0.4879INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2380 - root_mean_squared_error: 0.4878 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 54/200\n",
      "538/549 [============================>.] - ETA: 0s - loss: 0.2380 - root_mean_squared_error: 0.4878INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2379 - root_mean_squared_error: 0.4878 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 55/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2379 - root_mean_squared_error: 0.4877 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 56/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2378 - root_mean_squared_error: 0.4876 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 57/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2377 - root_mean_squared_error: 0.4876 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 58/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2377 - root_mean_squared_error: 0.4876 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 59/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2377 - root_mean_squared_error: 0.4875 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 60/200\n",
      "541/549 [============================>.] - ETA: 0s - loss: 0.2375 - root_mean_squared_error: 0.4873INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\alexp\\src\\NBA_Models\\src\\models\\model1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 2s 4ms/step - loss: 0.2376 - root_mean_squared_error: 0.4874 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 61/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2375 - root_mean_squared_error: 0.4874 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 62/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2374 - root_mean_squared_error: 0.4873 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 63/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2374 - root_mean_squared_error: 0.4872 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 64/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2373 - root_mean_squared_error: 0.4872 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 65/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2373 - root_mean_squared_error: 0.4871 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 66/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2372 - root_mean_squared_error: 0.4871 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 67/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2372 - root_mean_squared_error: 0.4870 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 68/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2371 - root_mean_squared_error: 0.4869 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 69/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2371 - root_mean_squared_error: 0.4869 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 70/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2370 - root_mean_squared_error: 0.4868 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 71/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2370 - root_mean_squared_error: 0.4868 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 72/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2369 - root_mean_squared_error: 0.4867 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 73/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2368 - root_mean_squared_error: 0.4867 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 74/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2368 - root_mean_squared_error: 0.4866 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 75/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2367 - root_mean_squared_error: 0.4865 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4916\n",
      "Epoch 76/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2367 - root_mean_squared_error: 0.4865 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 77/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2366 - root_mean_squared_error: 0.4865 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 78/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2366 - root_mean_squared_error: 0.4864 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 79/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2365 - root_mean_squared_error: 0.4863 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 80/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2365 - root_mean_squared_error: 0.4863 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 81/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2364 - root_mean_squared_error: 0.4862 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 82/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2364 - root_mean_squared_error: 0.4862 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 83/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2363 - root_mean_squared_error: 0.4861 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 84/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2363 - root_mean_squared_error: 0.4861 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 85/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2362 - root_mean_squared_error: 0.4860 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 86/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2361 - root_mean_squared_error: 0.4860 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 87/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2361 - root_mean_squared_error: 0.4859 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 88/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2360 - root_mean_squared_error: 0.4858 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 89/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2360 - root_mean_squared_error: 0.4858 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 90/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2359 - root_mean_squared_error: 0.4857 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 91/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2359 - root_mean_squared_error: 0.4857 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4917\n",
      "Epoch 92/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2359 - root_mean_squared_error: 0.4856 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 93/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2358 - root_mean_squared_error: 0.4856 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 94/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2357 - root_mean_squared_error: 0.4855 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 95/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2357 - root_mean_squared_error: 0.4854 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 96/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2356 - root_mean_squared_error: 0.4854 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 97/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2356 - root_mean_squared_error: 0.4854 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 98/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2355 - root_mean_squared_error: 0.4853 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 99/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2355 - root_mean_squared_error: 0.4853 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 100/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2354 - root_mean_squared_error: 0.4852 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 101/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2353 - root_mean_squared_error: 0.4851 - val_loss: 0.2422 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 102/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2353 - root_mean_squared_error: 0.4851 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 103/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2352 - root_mean_squared_error: 0.4850 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 104/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2352 - root_mean_squared_error: 0.4850 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 105/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2351 - root_mean_squared_error: 0.4849 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "Epoch 106/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2351 - root_mean_squared_error: 0.4849 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 107/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2350 - root_mean_squared_error: 0.4848 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 108/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2350 - root_mean_squared_error: 0.4847 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4919\n",
      "Epoch 109/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2350 - root_mean_squared_error: 0.4847 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 110/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2349 - root_mean_squared_error: 0.4846 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 111/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2348 - root_mean_squared_error: 0.4846 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 112/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2348 - root_mean_squared_error: 0.4845 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 113/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2347 - root_mean_squared_error: 0.4845 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 114/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2347 - root_mean_squared_error: 0.4844 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 115/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2346 - root_mean_squared_error: 0.4844 - val_loss: 0.2422 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 116/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2346 - root_mean_squared_error: 0.4843 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 117/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2345 - root_mean_squared_error: 0.4843 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 118/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2345 - root_mean_squared_error: 0.4842 - val_loss: 0.2422 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 119/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2344 - root_mean_squared_error: 0.4842 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4920\n",
      "Epoch 120/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2344 - root_mean_squared_error: 0.4841 - val_loss: 0.2422 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 121/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2343 - root_mean_squared_error: 0.4840 - val_loss: 0.2422 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 122/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2343 - root_mean_squared_error: 0.4840 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 123/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2342 - root_mean_squared_error: 0.4840 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 124/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2341 - root_mean_squared_error: 0.4839 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 125/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2341 - root_mean_squared_error: 0.4838 - val_loss: 0.2425 - val_root_mean_squared_error: 0.4924\n",
      "Epoch 126/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2340 - root_mean_squared_error: 0.4838 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 127/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2340 - root_mean_squared_error: 0.4837 - val_loss: 0.2424 - val_root_mean_squared_error: 0.4924\n",
      "Epoch 128/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2339 - root_mean_squared_error: 0.4836 - val_loss: 0.2422 - val_root_mean_squared_error: 0.4921\n",
      "Epoch 129/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2339 - root_mean_squared_error: 0.4836 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 130/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2338 - root_mean_squared_error: 0.4836 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 131/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2337 - root_mean_squared_error: 0.4835 - val_loss: 0.2425 - val_root_mean_squared_error: 0.4924\n",
      "Epoch 132/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2337 - root_mean_squared_error: 0.4834 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 133/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2337 - root_mean_squared_error: 0.4834 - val_loss: 0.2424 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 134/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2336 - root_mean_squared_error: 0.4833 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4922\n",
      "Epoch 135/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2336 - root_mean_squared_error: 0.4833 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 136/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2335 - root_mean_squared_error: 0.4832 - val_loss: 0.2424 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 137/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2334 - root_mean_squared_error: 0.4831 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 138/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2334 - root_mean_squared_error: 0.4831 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 139/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2333 - root_mean_squared_error: 0.4830 - val_loss: 0.2424 - val_root_mean_squared_error: 0.4923\n",
      "Epoch 140/200\n",
      "549/549 [==============================] - 1s 2ms/step - loss: 0.2333 - root_mean_squared_error: 0.4830 - val_loss: 0.2424 - val_root_mean_squared_error: 0.4924\n",
      "Epoch 141/200\n",
      " 84/549 [===>..........................] - ETA: 0s - loss: 0.2355 - root_mean_squared_error: 0.4853"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#for i in range(0,30):\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#    X_train, X_test_temp, y_train, y_test_temp = train_test_split(X_list[i], y_list[i], test_size=1 - train_ratio)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#    X_val, X_test, y_val, y_test = train_test_split(X_test_temp, y_test_temp, test_size=test_ratio/(test_ratio + validation_ratio)) \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for i in range(0,30):\n",
    "#    X_train, X_test_temp, y_train, y_test_temp = train_test_split(X_list[i], y_list[i], test_size=1 - train_ratio)\n",
    "#    X_val, X_test, y_val, y_test = train_test_split(X_test_temp, y_test_temp, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model1.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=200, callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model(\"C:\\\\Users\\\\alexp\\\\src\\\\NBA_Models\\\\src\\\\models\\\\model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds_raw = model1.predict(X_test)\n",
    "actual = y_test\n",
    "preds = []\n",
    "for i,pred in enumerate(preds_raw):\n",
    "    if pred[0] >=.5:\n",
    "        preds.append(1)\n",
    "    elif pred[0] <.5:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[659, 536],\n",
       "       [454, 694]], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "confusion_matrix(actual,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5774647887323944"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(actual,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5836837678721615"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(actual,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
